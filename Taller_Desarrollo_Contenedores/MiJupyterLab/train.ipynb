{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f310cc7",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cbc03a",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necesarios para carga, visualización y particionado de datos\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import RandomState\n",
    "import joblib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc9d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos desde el archivo CSV\n",
    "df = pd.read_csv('./Data/penguins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709002c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el DataFrame (vista rápida)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681df1fa",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d57d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspección inicial y limpieza básica (mostrar estructura y eliminar filas con NA)\n",
    "\n",
    "print(f\"Dimensiones originales: {df.shape}\")\n",
    "print(\"\\nPrimeras filas:\")\n",
    "print(df.head())\n",
    "print(\"\\nInformación del DataFrame:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "df_clean = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe29a27",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c2976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de columnas irrelevantes y comprobación de NA después de limpiar\n",
    "df_clean.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df_clean = df_clean.drop(columns=[\"year\"])\n",
    "\n",
    "print(f\"\\nDimensiones después de dropna y eliminación de 'year': {df_clean.shape}\")\n",
    "print(\"\\nValores faltantes después de limpieza:\")\n",
    "print(df_clean.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97660ac7",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b9ec3",
   "metadata": {},
   "source": [
    "## Feature Ingineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3fd00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar variables categóricas mediante one-hot encoding para modelado\n",
    "\n",
    "categorical_cols = df_clean.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "categorical_cols = [col for col in categorical_cols if col != \"species\"]\n",
    "\n",
    "print(f\"Columnas categóricas a codificar: {list(categorical_cols)}\")\n",
    "\n",
    "df_encoded = pd.get_dummies(\n",
    "    df_clean,\n",
    "    columns=categorical_cols,\n",
    "    drop_first=False,\n",
    "    dtype=int,\n",
    ")\n",
    "\n",
    "print(\"\\nColumnas después de la codificación:\")\n",
    "print(list(df_encoded.columns))\n",
    "print(f\"\\nDimensiones después de codificar: {df_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d756a1",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612acb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar características (X) y objetivo (y) y crear partición train/test estratificada\n",
    "\n",
    "y = df_encoded[\"species\"]\n",
    "\n",
    "X = df_encoded.drop(columns=[\"species\"])\n",
    "\n",
    "print(f\"Número de columnas de características: {X.shape[1]}\")\n",
    "print(f\"Columnas de características: {list(X.columns)}\")\n",
    "print(f\"\\nDimensiones de X: {X.shape}  |  Dimensiones de y: {y.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=RandomState(42),\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "print(f\"\\nDimensiones del conjunto de entrenamiento: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "print(f\"Dimensiones del conjunto de prueba:       X_test={X_test.shape}, y_test={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beb6c2b",
   "metadata": {},
   "source": [
    "# Model Creation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca81ee7",
   "metadata": {},
   "source": [
    "## Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e71119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir un clasificador RandomForest simple\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b366a1",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validación cruzada en entrenamiento (5-fold) para estimar estabilidad\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(f\"\\nCV (5-fold) - accuracy: mean={cv_scores.mean():.4f}, std={cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee23d89",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e952f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba y mostrar gráficas\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "print(cm)\n",
    "\n",
    "# Confusion matrix (heatmap)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Importancias de features (top 10)\n",
    "try:\n",
    "    importances = model.feature_importances_\n",
    "    feat_names = X.columns\n",
    "    top_idx = np.argsort(importances)[::-1][:10]\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.barplot(x=importances[top_idx], y=feat_names[top_idx])\n",
    "    plt.title('Top 10 Feature Importances')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(\"No se pudieron mostrar importancias de features:\", e)\n",
    "\n",
    "# Distribución: reales vs predichos\n",
    "actual_counts = y_test.value_counts().sort_index()\n",
    "pred_counts = pd.Series(y_pred).value_counts().reindex(actual_counts.index, fill_value=0)\n",
    "df_counts = pd.DataFrame({'actual': actual_counts, 'predicted': pred_counts})\n",
    "ax = df_counts.plot(kind='bar', figsize=(8,4))\n",
    "ax.set_title('Distribución: reales vs predichos')\n",
    "ax.set_xlabel('Clase')\n",
    "ax.set_ylabel('Conteo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dcacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado en formato pkl\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_path = f'./Models/model_random_forest_{timestamp}.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Modelo guardado en: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
